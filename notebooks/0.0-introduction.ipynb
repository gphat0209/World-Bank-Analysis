{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center; background-color: #5A96E3; font-family: 'Trebuchet MS', Arial, sans-serif; color: white; padding: 20px; font-size: 40px; font-weight: bold; border-radius: 0 0 0 0; box-shadow: 0px 6px 8px rgba(0, 0, 0, 0.2);\">\n",
    "  Stage 00 - A brief introductionðŸ“Œ\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow stages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generic workflow stages, however there are use cases with exceptions.\n",
    "1. Overview: \n",
    "    - Project title.\n",
    "    - What are the goals of the project (question or problem definition)?\n",
    "    - What is(are) dataset(s) ?\n",
    "    - Describe your team members.\n",
    "2. Data overview\n",
    "    - What is the source of data? Public? Crawled?\n",
    "    - What is the size of data?\n",
    "    - Brief introduction of data? What is the mean of each data properties?\n",
    "3. Data preparation and cleaning\n",
    "    - Acquire training and testing data.\n",
    "    - Wrangle, prepare, cleanse the data.\n",
    "    - Missing value treatment.\n",
    "    - Outlier detection and treatment.\n",
    "    - Feature engineering.\n",
    "4. Exploratory data analysis: Analyze, identify patterns, and explore the data.\n",
    "    - Univariate analysis.\n",
    "    - Bivariate analysis.\n",
    "    - Multivariate analysis.\n",
    "5. Data visualization\n",
    "    - Graphs, plots.\n",
    "    - Describe insights derivered from the visuals (combine with outside information from dataset that you found).\n",
    "6. Hypothesis testing and insights\n",
    "    - Statistical tests used\n",
    "    - Findings and insights\n",
    "7. Final report and presentation\n",
    "    - Key findings.\n",
    "    - What are limitations of the analysis?\n",
    "    - Propose recommendations for the next steps.\n",
    "8. References and data sources\n",
    "    - Structure dataset(s) and export links.\n",
    "    - Listing research papers or articles in reference section.\n",
    "9. Project structurization\n",
    "    - Notebooks source codes\n",
    "    - Python source codes\n",
    "    - Model binary files\n",
    "    - Data files\n",
    "    - Presentation or report files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow goals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data science solutions workflow solves for <font color=lightgreen>seven major goals (7C)</font>.\n",
    "\n",
    "<font color=lightgreen>**Classifying**</font>: Classifying involves classifying or categorizing data into different classes or categories. It's often used in classification problems where you aim to assign a label or category to data points. We may also want to understand the implications or correlation of different classes with our solution goal.\n",
    "\n",
    "<font color=lightgreen>**Correlating**</font>: Considering the available features within the training dataset, one wants to identify and analyse the relationships between them, and then determine which features within the dataset significantly contribute to our solution goal. Generally, correlating refers to the process of identifying and analysing relationships or correlations between different variables in the data. This step helps understand how variables are related to each other and is often part of exploratory data analysis (EDA). Correlating certain features may help in creating, completing, or correcting features.\n",
    "\n",
    "<font color=lightgreen>**Converting**</font>: In the data modelling stage, one should prepare the data to satisfy the requirements of learning algorithms. Converting data may involve changing the format or data type of variables to make them compatible with the analysis or modelling techniques. For example, converting text data into numerical features using techniques like one-hot encoding.\n",
    "\n",
    "<font color=lightgreen>**Completing**</font>: Due to many reasons, such as weak data collection techniques or low-quality data resources, datasets often have the imcompleteness characteristic. Completing the data involves addressing missing values in the dataset. Missing data can impact the quality of analysis and modelling, so it's important to handle missing values through imputation or other techniques.\n",
    "\n",
    "<font color=lightgreen>**Correcting**</font>: We may also search for errors or wrong values within features in the given training dataset and either confirm these values or reject the samples that include the errors. The process of finding and repairing faults or inconsistencies in a dataset is known as data rectification. Looking for outliers in our samples or attributes is one way. Another alternative is to eliminate a characteristic if it does not contribute to the analysis or has the potential to significantly affect the results.\n",
    "\n",
    "<font color=lightgreen>**Creating**</font>: Feature engineering or simply creating is a critical phase in the data science pipeline for creating new features or variables. It entails creating new variables or modifying existing ones in order to improve the performance of machine learning models.\n",
    "\n",
    "<font color=lightgreen>**Charting**</font>: Charting and data visualisation are critical components of the data science workflow. It entails producing charts, graphs, and other visual representations of data in order to better analyse patterns, trends, and insights. Data visualisation may help with communication and narrative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
